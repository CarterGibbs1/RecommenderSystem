{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to make everything object-oriented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Model + Evaluation\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderSystem:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.train_data = pd.DataFrame()\n",
    "        self.review_scaler = MinMaxScaler((0,5))\n",
    "        self.tfidf = TfidfVectorizer(stop_words='english')\n",
    "        self.tfidf_matrix = None\n",
    "        self.knn = NearestNeighbors(metric='cosine')\n",
    "        self.unique_users = []\n",
    "\n",
    "\n",
    "    def __preprocess_categories__(self, row):\n",
    "        # If nan\n",
    "        if isinstance(row, float):\n",
    "            return ''\n",
    "        m = re.match(r\"\\['(.*?)'\\]\", row)\n",
    "        if m:\n",
    "            return m.group(1)\n",
    "        return ''\n",
    "\n",
    "    # For training\n",
    "    def fit_transform(self, X : pd.DataFrame):\n",
    "        X_tmp = X.dropna(subset=('User_id', 'Title'))\n",
    "        merged_book_data = X_tmp[['User_id', 'Title', 'categories', 'review/score', 'description', 'authors']]\n",
    "        merged_book_data.loc[:,'categories'] = merged_book_data['categories'].apply(self.__preprocess_categories__)\n",
    "        merged_book_data['description'].fillna('', inplace=True)\n",
    "        merged_book_data['authors'].fillna('', inplace=True)\n",
    "        merged_book_data['combined_text_features'] = (\n",
    "            merged_book_data['description'] + ' ' +\n",
    "            merged_book_data['categories'] + ' ' +\n",
    "            merged_book_data['authors']).str.strip()\n",
    "\n",
    "        grouped_by_title = merged_book_data.groupby('Title')\n",
    "\n",
    "        # Average/Normalize Ratings of books\n",
    "        merged_book_data['average rating'] = grouped_by_title['review/score'].transform(lambda x : round(x.mean(), 2))\n",
    "        merged_book_data['average rating'] = self.review_scaler.fit_transform(merged_book_data[['average rating']])\n",
    "        merged_book_data['Title'] = merged_book_data['Title'].astype('category')\n",
    "\n",
    "        #merged_book_data.drop_duplicates(subset=('Title'), inplace = True)\n",
    "        merged_book_data.drop(['categories', 'authors', 'description'], axis=1, inplace=True)\n",
    "\n",
    "        merged_book_data.reset_index(drop=True, inplace=True)\n",
    "        self.tfidf_matrix = self.tfidf.fit_transform(merged_book_data['combined_text_features'])\n",
    "        self.knn.fit(self.tfidf_matrix)\n",
    "        self.unique_users = merged_book_data['User_id'].unique()\n",
    "        self.train_data = merged_book_data.copy()\n",
    "        return merged_book_data\n",
    "\n",
    "    # For testing\n",
    "    def transform(self, X):\n",
    "        X_tmp = X.dropna(subset=('User_id', 'Title'))\n",
    "        merged_book_data = X_tmp[['User_id', 'Title', 'categories', 'review/score', 'description', 'authors']]\n",
    "        merged_book_data.loc[:,'categories'] = merged_book_data['categories'].apply(self.__preprocess_categories__)\n",
    "        merged_book_data['description'].fillna('', inplace=True)\n",
    "        merged_book_data['authors'].fillna('', inplace=True)\n",
    "        merged_book_data['combined_text_features'] = (\n",
    "            merged_book_data['description'] + ' ' +\n",
    "            merged_book_data['categories'] + ' ' +\n",
    "            merged_book_data['authors']).str.strip()\n",
    "\n",
    "        grouped_by_title = merged_book_data.groupby('Title')\n",
    "\n",
    "        # Average/Normalize Ratings of books\n",
    "        merged_book_data['average rating'] = grouped_by_title['review/score'].transform(lambda x : round(x.mean(), 2))\n",
    "        merged_book_data['average rating'] = self.review_scaler.transform(merged_book_data[['average rating']])\n",
    "        merged_book_data['Title'] = merged_book_data['Title'].astype('category')\n",
    "\n",
    "        #merged_book_data.drop_duplicates(subset=('Title'), inplace = True)\n",
    "        merged_book_data.drop(['categories', 'authors', 'description'], axis=1, inplace=True)\n",
    "\n",
    "        merged_book_data.reset_index(drop=True, inplace=True)\n",
    "        return merged_book_data\n",
    "\n",
    "    def recommend(self, user_id, n_recommendations=5):\n",
    "        books_data = self.train_data\n",
    "        user_books = books_data[books_data['User_id'] == user_id]['Title'].unique()\n",
    "        if len(user_books) == 0:\n",
    "            print('User had no books')\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        user_indices = books_data[books_data['Title'].isin(user_books)].index\n",
    "        user_vectors = self.tfidf_matrix[user_indices]\n",
    "        user_profile_vector = user_vectors.mean(axis=0)\n",
    "\n",
    "        _, indices = self.knn.kneighbors(np.asarray(user_profile_vector), n_neighbors=len(user_indices) + 2 * n_recommendations + 1)\n",
    "        recommended_indices = []\n",
    "        recommended_books = []\n",
    "        for i in indices[0]:\n",
    "            if len(recommended_indices) == n_recommendations:\n",
    "                break\n",
    "            if books_data.iloc[i]['Title'] not in user_books \\\n",
    "            and books_data.iloc[i]['Title'] not in recommended_books:\n",
    "                recommended_books.append(books_data.iloc[i]['Title'])\n",
    "                recommended_indices.append(i)\n",
    "        return books_data.iloc[recommended_indices]\n",
    "\n",
    "    # Model evaluation\n",
    "    def precision_k(self, recommended, relevant, k):\n",
    "        rec = recommended[:k]\n",
    "        rel = set(rec) & set(relevant)\n",
    "        return len(rel) / k\n",
    "\n",
    "    def recall_k(self, recommended, relevant, k):\n",
    "        rec = recommended[:k]\n",
    "        rel = set(rec) & set(relevant)\n",
    "        return len(rel) / len(relevant) if relevant else 0\n",
    "\n",
    "    def mean_reciprocal_rank(self, recommended, relevant):\n",
    "        for rank, rec in enumerate(recommended, start=1):\n",
    "            if rec in relevant:\n",
    "                return 1 / rank\n",
    "        return 0\n",
    "\n",
    "    def evaluate_recommender(self, X, n_recommendations=5):\n",
    "        precision_scores = []\n",
    "        recall_scores = []\n",
    "        mrr_scores = []\n",
    "        \n",
    "        for user_id in tqdm(X['User_id'].unique()):\n",
    "            user_test_books = X[X['User_id'] == user_id]['Title'].tolist()\n",
    "            \n",
    "            recommended_books = self.recommend(\n",
    "                user_id=user_id,\n",
    "                n_recommendations=n_recommendations\n",
    "            )['Title'].tolist()\n",
    "            \n",
    "            if not recommended_books:\n",
    "                continue\n",
    "            \n",
    "            precision_scores.append(self.precision_k(recommended_books, user_test_books, k=n_recommendations))\n",
    "            recall_scores.append(self.recall_k(recommended_books, user_test_books, k=n_recommendations))\n",
    "            mrr_scores.append(self.mean_reciprocal_rank(recommended_books, user_test_books))\n",
    "\n",
    "        \n",
    "        return {\n",
    "            \"Precision\": np.average(precision_scores),\n",
    "            \"Recall\": np.average(recall_scores),\n",
    "            \"MRR\": np.average(mrr_scores)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data = pd.read_csv('data/books_data.csv')\n",
    "books_rating_data = pd.read_csv('data/Books_rating.csv')\n",
    "\n",
    "bd_X_train, bd_X_test = train_test_split(book_data)\n",
    "brd_X_train, brd_X_test = train_test_split(books_rating_data)\n",
    "\n",
    "X_train = bd_X_train.merge(brd_X_train, how='left', on='Title')\n",
    "X_test = bd_X_test.merge(brd_X_test, how='left', on='Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carte\\AppData\\Local\\Temp\\ipykernel_18064\\184077934.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_book_data['description'].fillna('', inplace=True)\n",
      "C:\\Users\\carte\\AppData\\Local\\Temp\\ipykernel_18064\\184077934.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_book_data['description'].fillna('', inplace=True)\n",
      "C:\\Users\\carte\\AppData\\Local\\Temp\\ipykernel_18064\\184077934.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_book_data['authors'].fillna('', inplace=True)\n",
      "C:\\Users\\carte\\AppData\\Local\\Temp\\ipykernel_18064\\184077934.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_book_data['authors'].fillna('', inplace=True)\n",
      "C:\\Users\\carte\\AppData\\Local\\Temp\\ipykernel_18064\\184077934.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_book_data['combined_text_features'] = (\n",
      "C:\\Users\\carte\\AppData\\Local\\Temp\\ipykernel_18064\\184077934.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_book_data['average rating'] = grouped_by_title['review/score'].transform(lambda x : round(x.mean(), 2))\n",
      "C:\\Users\\carte\\AppData\\Local\\Temp\\ipykernel_18064\\184077934.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_book_data['average rating'] = self.review_scaler.fit_transform(merged_book_data[['average rating']])\n",
      "C:\\Users\\carte\\AppData\\Local\\Temp\\ipykernel_18064\\184077934.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_book_data['Title'] = merged_book_data['Title'].astype('category')\n",
      "C:\\Users\\carte\\AppData\\Local\\Temp\\ipykernel_18064\\184077934.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_book_data.drop(['categories', 'authors', 'description'], axis=1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Title</th>\n",
       "      <th>review/score</th>\n",
       "      <th>combined_text_features</th>\n",
       "      <th>average rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1MZB6UBKOVSK0</td>\n",
       "      <td>Little wars: A game for boys from twelve years...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Little Wars is a set of rules for playing with...</td>\n",
       "      <td>3.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUTBHG6070SL4</td>\n",
       "      <td>Little wars: A game for boys from twelve years...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Little Wars is a set of rules for playing with...</td>\n",
       "      <td>3.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2N1VOV3N4ZR22</td>\n",
       "      <td>Little wars: A game for boys from twelve years...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Little Wars is a set of rules for playing with...</td>\n",
       "      <td>3.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A7H4LNXXJ3DM6</td>\n",
       "      <td>Little wars: A game for boys from twelve years...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Little Wars is a set of rules for playing with...</td>\n",
       "      <td>3.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHA1U1QCT41HC</td>\n",
       "      <td>Little wars: A game for boys from twelve years...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Little Wars is a set of rules for playing with...</td>\n",
       "      <td>3.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          User_id                                              Title  \\\n",
       "0  A1MZB6UBKOVSK0  Little wars: A game for boys from twelve years...   \n",
       "1   AUTBHG6070SL4  Little wars: A game for boys from twelve years...   \n",
       "2  A2N1VOV3N4ZR22  Little wars: A game for boys from twelve years...   \n",
       "3   A7H4LNXXJ3DM6  Little wars: A game for boys from twelve years...   \n",
       "4   AHA1U1QCT41HC  Little wars: A game for boys from twelve years...   \n",
       "\n",
       "   review/score                             combined_text_features  \\\n",
       "0           3.0  Little Wars is a set of rules for playing with...   \n",
       "1           4.0  Little Wars is a set of rules for playing with...   \n",
       "2           4.0  Little Wars is a set of rules for playing with...   \n",
       "3           4.0  Little Wars is a set of rules for playing with...   \n",
       "4           5.0  Little Wars is a set of rules for playing with...   \n",
       "\n",
       "   average rating  \n",
       "0           3.125  \n",
       "1           3.125  \n",
       "2           3.125  \n",
       "3           3.125  \n",
       "4           3.125  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting\n",
    "recommender = RecommenderSystem()\n",
    "X_train_processed = recommender.fit_transform(X_train)\n",
    "X_train_processed[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Title</th>\n",
       "      <th>review/score</th>\n",
       "      <th>combined_text_features</th>\n",
       "      <th>average rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>A1DAOL3NMHEPLS</td>\n",
       "      <td>Earth abides</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Returning from a field trip, Isherwood William...</td>\n",
       "      <td>3.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>A1DAOL3NMHEPLS</td>\n",
       "      <td>Doctor from Lhasa</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>2.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13480</th>\n",
       "      <td>A1DAOL3NMHEPLS</td>\n",
       "      <td>Gladiator at Law</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CAUTION! You are about to enter a world... whe...</td>\n",
       "      <td>4.3750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101987</th>\n",
       "      <td>A1DAOL3NMHEPLS</td>\n",
       "      <td>The other side of the sky</td>\n",
       "      <td>5.0</td>\n",
       "      <td>\"Amie Kaufman and Meagan Spooner prove they ar...</td>\n",
       "      <td>4.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113914</th>\n",
       "      <td>A1DAOL3NMHEPLS</td>\n",
       "      <td>ACME Catalog: Quality is Our #1 Dream</td>\n",
       "      <td>4.0</td>\n",
       "      <td>With such offerings as jet-powered pogo sticks...</td>\n",
       "      <td>4.5625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129933</th>\n",
       "      <td>A1DAOL3NMHEPLS</td>\n",
       "      <td>Little Scarlet: An Easy Rawlins Mystery</td>\n",
       "      <td>4.0</td>\n",
       "      <td>When a man who fled the 1965 Watts riots is su...</td>\n",
       "      <td>4.5375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191999</th>\n",
       "      <td>A1DAOL3NMHEPLS</td>\n",
       "      <td>The Darwin Awards: Evolution in Action</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The hilarious New York Times bestselling pheno...</td>\n",
       "      <td>3.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310658</th>\n",
       "      <td>A1DAOL3NMHEPLS</td>\n",
       "      <td>This Perfect Day</td>\n",
       "      <td>5.0</td>\n",
       "      <td>By the author of Rosemary‘s Baby, a horrifying...</td>\n",
       "      <td>4.5250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775139</th>\n",
       "      <td>A1DAOL3NMHEPLS</td>\n",
       "      <td>Stupidest Angel, The LP</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Dennis Wilson, Beach Boys drummer, 60's pin-up...</td>\n",
       "      <td>4.1625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793298</th>\n",
       "      <td>A1DAOL3NMHEPLS</td>\n",
       "      <td>Nightmare At 20,000 Feet (Turtleback School &amp; ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>In één avond verdwijnen vier jonge kinderen op...</td>\n",
       "      <td>4.1625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006232</th>\n",
       "      <td>A1DAOL3NMHEPLS</td>\n",
       "      <td>The Spiral Calendar and Its Effect on Financia...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Reveals one of the most exciting market foreca...</td>\n",
       "      <td>3.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027104</th>\n",
       "      <td>A1DAOL3NMHEPLS</td>\n",
       "      <td>Martians, Go Home</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Little, green, obnoxious Martians are everywhe...</td>\n",
       "      <td>4.6875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108604</th>\n",
       "      <td>A1DAOL3NMHEPLS</td>\n",
       "      <td>Portrait of a Killer: Jack the Ripper - Case C...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Now updated with new material that brings the ...</td>\n",
       "      <td>1.9625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135149</th>\n",
       "      <td>A1DAOL3NMHEPLS</td>\n",
       "      <td>The Castle of Iron</td>\n",
       "      <td>4.0</td>\n",
       "      <td>English fiction ['Lyon Sprague De Camp', 'Flet...</td>\n",
       "      <td>4.5875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141732</th>\n",
       "      <td>A1DAOL3NMHEPLS</td>\n",
       "      <td>Coyote: A Novel of Interstellar Exploration</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Twenty years following the revolution that won...</td>\n",
       "      <td>3.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232464</th>\n",
       "      <td>A1DAOL3NMHEPLS</td>\n",
       "      <td>Waldo and Magic, Inc.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NEW INTRODUCTION BY TIM POWERS! Compelling SF ...</td>\n",
       "      <td>3.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311227</th>\n",
       "      <td>A1DAOL3NMHEPLS</td>\n",
       "      <td>The Book of Tea</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The Book of Tea describes all aspects of the J...</td>\n",
       "      <td>3.8125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                User_id                                              Title  \\\n",
       "343      A1DAOL3NMHEPLS                                       Earth abides   \n",
       "3731     A1DAOL3NMHEPLS                                  Doctor from Lhasa   \n",
       "13480    A1DAOL3NMHEPLS                                   Gladiator at Law   \n",
       "101987   A1DAOL3NMHEPLS                          The other side of the sky   \n",
       "113914   A1DAOL3NMHEPLS              ACME Catalog: Quality is Our #1 Dream   \n",
       "129933   A1DAOL3NMHEPLS            Little Scarlet: An Easy Rawlins Mystery   \n",
       "191999   A1DAOL3NMHEPLS             The Darwin Awards: Evolution in Action   \n",
       "310658   A1DAOL3NMHEPLS                                   This Perfect Day   \n",
       "775139   A1DAOL3NMHEPLS                            Stupidest Angel, The LP   \n",
       "793298   A1DAOL3NMHEPLS  Nightmare At 20,000 Feet (Turtleback School & ...   \n",
       "1006232  A1DAOL3NMHEPLS  The Spiral Calendar and Its Effect on Financia...   \n",
       "1027104  A1DAOL3NMHEPLS                                  Martians, Go Home   \n",
       "1108604  A1DAOL3NMHEPLS  Portrait of a Killer: Jack the Ripper - Case C...   \n",
       "1135149  A1DAOL3NMHEPLS                                 The Castle of Iron   \n",
       "1141732  A1DAOL3NMHEPLS        Coyote: A Novel of Interstellar Exploration   \n",
       "1232464  A1DAOL3NMHEPLS                              Waldo and Magic, Inc.   \n",
       "1311227  A1DAOL3NMHEPLS                                    The Book of Tea   \n",
       "\n",
       "         review/score                             combined_text_features  \\\n",
       "343               5.0  Returning from a field trip, Isherwood William...   \n",
       "3731              1.0                                                      \n",
       "13480             5.0  CAUTION! You are about to enter a world... whe...   \n",
       "101987            5.0  \"Amie Kaufman and Meagan Spooner prove they ar...   \n",
       "113914            4.0  With such offerings as jet-powered pogo sticks...   \n",
       "129933            4.0  When a man who fled the 1965 Watts riots is su...   \n",
       "191999            3.0  The hilarious New York Times bestselling pheno...   \n",
       "310658            5.0  By the author of Rosemary‘s Baby, a horrifying...   \n",
       "775139            5.0  Dennis Wilson, Beach Boys drummer, 60's pin-up...   \n",
       "793298            4.0  In één avond verdwijnen vier jonge kinderen op...   \n",
       "1006232           3.0  Reveals one of the most exciting market foreca...   \n",
       "1027104           5.0  Little, green, obnoxious Martians are everywhe...   \n",
       "1108604           3.0  Now updated with new material that brings the ...   \n",
       "1135149           4.0  English fiction ['Lyon Sprague De Camp', 'Flet...   \n",
       "1141732           3.0  Twenty years following the revolution that won...   \n",
       "1232464           3.0  NEW INTRODUCTION BY TIM POWERS! Compelling SF ...   \n",
       "1311227           5.0  The Book of Tea describes all aspects of the J...   \n",
       "\n",
       "         average rating  \n",
       "343              3.7000  \n",
       "3731             2.8125  \n",
       "13480            4.3750  \n",
       "101987           4.6875  \n",
       "113914           4.5625  \n",
       "129933           4.5375  \n",
       "191999           3.3000  \n",
       "310658           4.5250  \n",
       "775139           4.1625  \n",
       "793298           4.1625  \n",
       "1006232          3.5000  \n",
       "1027104          4.6875  \n",
       "1108604          1.9625  \n",
       "1135149          4.5875  \n",
       "1141732          3.0625  \n",
       "1232464          3.1250  \n",
       "1311227          3.8125  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example recommendation\n",
    "sample_user_id = X_train_processed['User_id'].iloc[343]\n",
    "# First view what the user currently has read.\n",
    "X_train_processed[X_train_processed['User_id'] == sample_user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Title</th>\n",
       "      <th>review/score</th>\n",
       "      <th>combined_text_features</th>\n",
       "      <th>average rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>421762</th>\n",
       "      <td>A3ULNP89GTG7P</td>\n",
       "      <td>Jack the Ripper: End of a Legend</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I've got no time to tell you how I came to be ...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636726</th>\n",
       "      <td>A2IZP47QL229P3</td>\n",
       "      <td>Jack the Ripper: Crime Scene Investigation</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Over 100 years have elapsed since what is beli...</td>\n",
       "      <td>0.4125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538497</th>\n",
       "      <td>A3NER4ZESH9JSN</td>\n",
       "      <td>Jack the Ripper: First American Serial Killer</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stewart Evans is a policeman whose hobby is co...</td>\n",
       "      <td>3.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065445</th>\n",
       "      <td>A3H4RXHJLYDCG6</td>\n",
       "      <td>The Mammoth Book of Jack the Ripper (Mammoth B...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Updated and expanded edition of the fullest ev...</td>\n",
       "      <td>4.1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305801</th>\n",
       "      <td>A2TJYYHTC1M7HH</td>\n",
       "      <td>The American Murders of Jack the Ripper</td>\n",
       "      <td>1.0</td>\n",
       "      <td>For the first time, the American murders of Ja...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                User_id                                              Title  \\\n",
       "421762    A3ULNP89GTG7P                   Jack the Ripper: End of a Legend   \n",
       "636726   A2IZP47QL229P3         Jack the Ripper: Crime Scene Investigation   \n",
       "538497   A3NER4ZESH9JSN      Jack the Ripper: First American Serial Killer   \n",
       "1065445  A3H4RXHJLYDCG6  The Mammoth Book of Jack the Ripper (Mammoth B...   \n",
       "1305801  A2TJYYHTC1M7HH            The American Murders of Jack the Ripper   \n",
       "\n",
       "         review/score                             combined_text_features  \\\n",
       "421762            1.0  I've got no time to tell you how I came to be ...   \n",
       "636726            1.0  Over 100 years have elapsed since what is beli...   \n",
       "538497            3.0  Stewart Evans is a policeman whose hobby is co...   \n",
       "1065445           5.0  Updated and expanded edition of the fullest ev...   \n",
       "1305801           1.0  For the first time, the American murders of Ja...   \n",
       "\n",
       "         average rating  \n",
       "421762           0.0000  \n",
       "636726           0.4125  \n",
       "538497           3.7500  \n",
       "1065445          4.1125  \n",
       "1305801          0.0000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then view recommendations\n",
    "recommender.recommend(sample_user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 162/663854 [05:40<386:55:34,  2.10s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluation on the training set first\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mrecommender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_recommender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_processed\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 123\u001b[0m, in \u001b[0;36mRecommenderSystem.evaluate_recommender\u001b[1;34m(self, X, n_recommendations)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user_id \u001b[38;5;129;01min\u001b[39;00m tqdm(X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()):\n\u001b[0;32m    121\u001b[0m     user_test_books \u001b[38;5;241m=\u001b[39m X[X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUser_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m user_id][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m--> 123\u001b[0m     recommended_books \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecommend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_recommendations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_recommendations\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m recommended_books:\n\u001b[0;32m    129\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 86\u001b[0m, in \u001b[0;36mRecommenderSystem.recommend\u001b[1;34m(self, user_id, n_recommendations)\u001b[0m\n\u001b[0;32m     83\u001b[0m user_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtfidf_matrix[user_indices]\n\u001b[0;32m     84\u001b[0m user_profile_vector \u001b[38;5;241m=\u001b[39m user_vectors\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 86\u001b[0m _, indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_profile_vector\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muser_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_recommendations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m recommended_indices \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     88\u001b[0m recommended_books \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32md:\\conda\\envs\\ML\\lib\\site-packages\\sklearn\\neighbors\\_base.py:886\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    883\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m         kwds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meffective_metric_params_\n\u001b[1;32m--> 886\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpairwise_distances_chunked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreduce_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffective_metric_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mball_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkd_tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32md:\\conda\\envs\\ML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2172\u001b[0m, in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   2170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2171\u001b[0m     X_chunk \u001b[38;5;241m=\u001b[39m X[sl]\n\u001b[1;32m-> 2172\u001b[0m D_chunk \u001b[38;5;241m=\u001b[39m pairwise_distances(X_chunk, Y, metric\u001b[38;5;241m=\u001b[39mmetric, n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   2173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (X \u001b[38;5;129;01mis\u001b[39;00m Y \u001b[38;5;129;01mor\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   2174\u001b[0m     metric, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2175\u001b[0m ) \u001b[38;5;129;01mis\u001b[39;00m euclidean_distances:\n\u001b[0;32m   2176\u001b[0m     \u001b[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001b[39;00m\n\u001b[0;32m   2177\u001b[0m     \u001b[38;5;66;03m# i.e. \"l2\"\u001b[39;00m\n\u001b[0;32m   2178\u001b[0m     D_chunk\u001b[38;5;241m.\u001b[39mflat[sl\u001b[38;5;241m.\u001b[39mstart :: _num_samples(X) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32md:\\conda\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32md:\\conda\\envs\\ML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2375\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   2372\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m distance\u001b[38;5;241m.\u001b[39msquareform(distance\u001b[38;5;241m.\u001b[39mpdist(X, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m   2373\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(distance\u001b[38;5;241m.\u001b[39mcdist, metric\u001b[38;5;241m=\u001b[39mmetric, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m-> 2375\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32md:\\conda\\envs\\ML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1893\u001b[0m, in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1890\u001b[0m X, Y, dtype \u001b[38;5;241m=\u001b[39m _return_float_dtype(X, Y)\n\u001b[0;32m   1892\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(n_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1893\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(X, Y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1895\u001b[0m \u001b[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001b[39;00m\n\u001b[0;32m   1896\u001b[0m fd \u001b[38;5;241m=\u001b[39m delayed(_dist_wrapper)\n",
      "File \u001b[1;32md:\\conda\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\envs\\ML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1130\u001b[0m, in \u001b[0;36mcosine_distances\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine distance between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m \n\u001b[0;32m   1097\u001b[0m \u001b[38;5;124;03mCosine distance is defined as 1.0 minus the cosine similarity.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;124;03m       [0.42..., 0.18...]])\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;66;03m# 1.0 - cosine_similarity(X, Y) without copy\u001b[39;00m\n\u001b[1;32m-> 1130\u001b[0m S \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m S \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1132\u001b[0m S \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32md:\\conda\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32md:\\conda\\envs\\ML\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1687\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 1687\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_normalized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[1;32md:\\conda\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\extmath.py:205\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    203\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    208\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    212\u001b[0m ):\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "File \u001b[1;32md:\\conda\\envs\\ML\\lib\\site-packages\\scipy\\sparse\\_base.py:675\u001b[0m, in \u001b[0;36m_spbase.__rmatmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    673\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    674\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rmatmul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\conda\\envs\\ML\\lib\\site-packages\\scipy\\sparse\\_base.py:656\u001b[0m, in \u001b[0;36m_spbase._rmatmul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m    655\u001b[0m     tr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(other)\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[1;32m--> 656\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matmul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[1;32md:\\conda\\envs\\ML\\lib\\site-packages\\scipy\\sparse\\_base.py:566\u001b[0m, in \u001b[0;36m_spbase._matmul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_matmul_vector(other)\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m (N, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 566\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matmul_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    568\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32md:\\conda\\envs\\ML\\lib\\site-packages\\scipy\\sparse\\_compressed.py:492\u001b[0m, in \u001b[0;36m_cs_matrix._matmul_vector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# csr_matvec or csc_matvec\u001b[39;00m\n\u001b[0;32m    491\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matvec\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 492\u001b[0m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluation on the training set first\n",
    "recommender.evaluate_recommender(X_train_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation using testing data\n",
    "X_test_processed = recommender.transform(X_test)\n",
    "recommender.evaluate_recommender(X_test_processed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
